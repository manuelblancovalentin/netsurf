{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/Users/mbvalentin/scripts/wsbmr/dev')\n",
    "sys.path.append('/Users/mbvalentin/scripts/fkeras')\n",
    "sys.path.append('/Users/mbvalentin/scripts/qkeras')\n",
    "sys.path.append('/Users/mbvalentin/scripts/DynamicTable')\n",
    "sys.path.append('/Users/mbvalentin/scripts/tensorplot')\n",
    "\n",
    "# Basic modules \n",
    "import os \n",
    "\n",
    "# Let's add our custom wsbmr code \n",
    "import wsbmr\n",
    "\n",
    "# Hashlib\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the wsbmr nodus db connector \n",
    "nodus_db = wsbmr.nodus_db\n",
    "# Job manager obj\n",
    "jm = nodus_db.job_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define benchmark, prune, etc. \n",
    "benchmarks = ['autompg']\n",
    "quants = [\"num_bits=6 integer=0\"]#, \"num_bits=8 integer=0\", \"num_bits=16 integer=0\"]\n",
    "prunes = [0.0] #wsbmr.config.DEFAULT_PRUNINGS\n",
    "protection_range = [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "ber_range = [0.001, 0.00167, 0.00278, 0.00464, 0.00774, 0.01, 0.01292, 0.02154, 0.03594, 0.05995, 0.1]\n",
    "methods = ['bitwise_msb', 'random', 'layerwise_first', 'layerwise_last', 'weight_abs_value', 'hirescam_norm', 'hiresdelta', 'hessian', 'hessiandelta']\n",
    "\n",
    "# Define the common format\n",
    "def format_cmd(benchmark, prune, protection_range, ber_range):\n",
    "    return f\"\"\"python wsbmr \\\\\n",
    "    --benchmarks_dir /Users/mbvalentin/scripts/wsbmr/benchmarks \\\\\n",
    "    --datasets_dir /Users/mbvalentin/scripts/wsbmr/datasets \\\\\n",
    "    --benchmark {benchmark} \\\\\n",
    "    --bits_config num_bits=6 integer=0 \\\\\n",
    "    --prune {prune} \\\\\n",
    "    --protection_range {' '.join(map(str, protection_range))} \\\\\n",
    "    --ber_range {' '.join(map(str, ber_range))}\"\"\"\n",
    "\n",
    "def format_extra(cfg):\n",
    "    return f\"\"\" \\\\\n",
    "        --method {cfg['method']} \\\\\n",
    "        --method_suffix {cfg['method_suffix']} \\\\\n",
    "        --method_kws {cfg['method_kws']} \\\\\n",
    "        --plot \"\"\"\n",
    "\n",
    "\"\"\" Main name of the processes \"\"\"\n",
    "# We need to train a model for each combo of benchmark, quantization and prune factor\n",
    "prev_dependency = []\n",
    "for b in benchmarks:\n",
    "    for q in quants:\n",
    "        for p in prunes:\n",
    "            # Name\n",
    "            name = f\"user::{b}::{q}::{p}\"\n",
    "\n",
    "            # Get the common part for each job in this case\n",
    "            common = format_cmd(benchmark=b, prune=p, protection_range=protection_range, ber_range=ber_range)\n",
    "\n",
    "            # This common part is basically the job that we will run first, cause it will make sure\n",
    "            # we train the model and save it. \n",
    "            # this job will be parent of all the rest of the jobs, which will be dependent on this one.\n",
    "            # This means, the rest of the jobs (the ones that will get the actual results) will only start\n",
    "            # after the parent job is done.\n",
    "            hash = hashlib.md5(common.encode()).hexdigest()\n",
    "\n",
    "            # Create job for parent\n",
    "            job_id_parent, job_parent = jm.create_job(\n",
    "                name = f\"autompg_{hash}\",\n",
    "                parent_caller = name,\n",
    "                job_type = \"command\",\n",
    "                command = common\n",
    "            )\n",
    "\n",
    "            # Create job for each method \n",
    "            for m in methods:\n",
    "                job_cmd = common + '\\\\ ' + format_extra(wsbmr.config.config_per_method[m])\n",
    "                \n",
    "                # Get hash \n",
    "                hash = hashlib.md5(job_cmd.encode()).hexdigest()\n",
    "\n",
    "\n",
    "                # Create job\n",
    "                job_id, job = jm.create_job(\n",
    "                    name = f\"model_training_{hash}\",\n",
    "                    parent_caller = f'{name}::{m}',\n",
    "                    job_type = \"command\",\n",
    "                    command = job_cmd,\n",
    "                    dependencies = [job_id_parent]\n",
    "                )\n",
    "            \n",
    "            # Before moving to the next benchmark, quantization and prune factor, let's wait for the parent job\n",
    "            jm.wait_for_job_completion(job_id)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsbmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
