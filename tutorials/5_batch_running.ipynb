{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch running equal ranking time (hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /Users/mbvalentin/scripts/netsurf to sys.path\n",
      "[INFO] - Added qkeras to sys.path from /Users/mbvalentin/scripts/netsurf/qkeras\n",
      "[INFO] - Added pergamos to sys.path from /Users/mbvalentin/scripts/netsurf/pergamos\n",
      "[INFO] - Loaded theme: default\n",
      "\u001b[48;2;141;47;102m\u001b[48;2;141;47;102m \u001b[48;2;117;39;85m \u001b[48;2;94;31;68m \u001b[48;2;70;23;51m \u001b[48;2;46;15;33m \u001b[48;2;23;7;17m \u001b[48;2;0;0;0m \u001b[48;2;23;7;17m \u001b[48;2;46;15;33m \u001b[48;2;70;23;51m \u001b[48;2;94;31;68m \u001b[48;2;117;39;85m \u001b[48;2;141;47;102m      \u001b[48;2;249;230;207m  ‚ññ ‚ñó  ‚ñô‚ñô  ‚ñò‚ñù‚ñô‚ñõ‚ñò \u001b[0m\n",
      "\u001b[48;2;141;47;102m\u001b[48;2;141;47;102m \u001b[48;2;117;39;85m \u001b[48;2;94;31;68m \u001b[48;2;70;23;51mêåç\u001b[48;2;46;15;33m \u001b[48;2;23;7;17m‚Ü†\u001b[48;2;0;0;0m‚åæ\u001b[48;2;23;7;17m‚Üû\u001b[48;2;46;15;33m \u001b[48;2;70;23;51mêåÉ\u001b[48;2;94;31;68m \u001b[48;2;117;39;85mêåñ\u001b[48;2;141;47;102m êåî    \u001b[48;2;250;198;122m ‚ñó ‚ñù  ‚ñú‚ñò‚ññ ‚ñû‚ñô  ‚ñõ‚ñò \u001b[0m\n",
      "\u001b[48;2;141;47;102m\u001b[48;2;141;47;102m \u001b[48;2;117;39;85m \u001b[48;2;94;31;68m \u001b[48;2;70;23;51m \u001b[48;2;46;15;33m \u001b[48;2;23;7;17m \u001b[48;2;0;0;0m \u001b[48;2;23;7;17m \u001b[48;2;46;15;33m \u001b[48;2;70;23;51m \u001b[48;2;94;31;68m \u001b[48;2;117;39;85m \u001b[48;2;141;47;102m      \u001b[48;2;250;198;122m    ‚ñö‚ñó‚ñù‚ñó   ‚ñõ ‚ñö‚ñû  \u001b[0m\n",
      "\n",
      "Logging to file: /Users/mbvalentin/.nodus/nodus_20250405_062157.log\n",
      "Found config file: /Users/mbvalentin/.netsurf/config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- Date: 05/Apr/2025\n",
      "‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
      "‚ï∞ INFO ‚îÄ‚î§ 06:21:57.08 ‚îÇ - Nodus initialized\n",
      "        ‚îÇ 06:21:57.08 ‚îÇ - Nodus version: 0.1.0\n",
      "        ‚îÇ 06:21:57.08 ‚îÇ - Nodus imported\n",
      "        ‚îÇ 06:21:57.08 ‚îÇ - Jobs imported\n",
      "        ‚îÇ 06:21:57.08 ‚îÇ - JobManager imported\n",
      "        ‚îÇ 06:21:57.08 ‚îÇ - Nodus ready to use\n",
      "        ‚îÇ 06:21:57.26 ‚îÇ - Created jobs table in NodusDB instance 'netsurf_db'\n",
      "        ‚îÇ 06:21:57.26 ‚îÇ - Created job_dependencies table in NodusDB instance 'netsurf_db'\n",
      "        ‚îÇ 06:21:57.26 ‚îÇ - Added NodusDB instance 'netsurf_db' linked to database 'netsurf_db'\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "# Import datetime to get today's date\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\" Let's add our custom netsurf code \"\"\"\n",
    "import netsurf\n",
    "\n",
    "\"\"\" Get netsurf path \"\"\"\n",
    "import os \n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(netsurf.__file__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pergamos as pg\n",
    "\n",
    "benchmarks = ['fashion_mnist_fnn', 'mnist_fnn', 'autompg', 'smartpixel_small']\n",
    "# Set variables\n",
    "qschemes = [\"q<6,2,1>\", \"q<6,0,1>\", \"q<6,0,0>\", \"q<16,1,1>\"]\n",
    "prunings = [0.0, 0.125, 0.25]\n",
    "prerank = True\n",
    "\n",
    "# combine them \n",
    "combs = list(itertools.product(qschemes, prunings))\n",
    "\n",
    "for (qscheme, pruning) in combs:\n",
    "    \n",
    "    \"\"\" First of all, let's define a quantization Scheme \"\"\"\n",
    "    Q = netsurf.QuantizationScheme(qscheme)\n",
    "    print(Q)\n",
    "    \n",
    "    # Set filename\n",
    "    benchmarks_dir = os.path.join(parent_dir, 'benchmarks')\n",
    "    datasets_dir = os.path.join(parent_dir, 'datasets')\n",
    "\n",
    "    filename = f\"2_qpolar_{Q._scheme_str.no_special_chars()}_bmarks_{'_'.join(benchmarks)}_prune{str(pruning).replace('.','_')}.html\"\n",
    "    print(filename)\n",
    "    doc = pg.Document(filename, theme=\"default\")\n",
    "    doc.required_scripts.add('mathjax')\n",
    "\n",
    "\n",
    "    \"\"\" Add a title to the document \"\"\"\n",
    "    doc.append(pg.Markdown(f\"\"\"# Benchmarks Quantization Assertion\n",
    "    > Author: Manuel B Valentin\n",
    "\n",
    "    > Creation date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "    > Project: netsurf\n",
    "\n",
    "    > Used packages: netsurf, tensorflow, numpy, matplotlib, pergamos\n",
    "            \n",
    "    \"\"\"))\n",
    "\n",
    "    # Add a tab container\n",
    "    tabs = pg.TabbedContainer({'Motivation': [], \n",
    "                            'Pre-training analysis': [],\n",
    "                            'Training': [],\n",
    "                                'Post-Training': [],\n",
    "                            'BER Injection': [],\n",
    "                            'Conclusions': []})\n",
    "\n",
    "    # Get individual tabs\n",
    "    tabmotivation = tabs['Motivation']\n",
    "    tabpretraining = tabs['Pre-training analysis']\n",
    "    tabtraining = tabs['Training']\n",
    "    tabposttraining = tabs['Post-Training']\n",
    "    tabber = tabs['BER Injection']\n",
    "    tabconclusions = tabs['Conclusions']\n",
    "\n",
    "    # Add to documnt\n",
    "    doc.append(tabs)\n",
    "\n",
    "    # Add a markdown description of what we want to achieve with this report in the first tab\n",
    "    md = r\"\"\"\n",
    "    ## 1. Loss Taylor expansion\n",
    "\n",
    "    Given a loss function $\\mathcal{L}(w)$, where $w$ is the vector of all weights in the network, the Taylor expansion around some point $w_0$ (say, the trained weights) for a small perturbation $\\Delta w$ is:\n",
    "\n",
    "    $$\\mathcal{L}(w_0 + \\Delta w) \\approx \\mathcal{L}(w_0) + \\nabla \\mathcal{L}(w_0)^T \\Delta w + \\frac{1}{2} \\Delta w^T H \\Delta w$$\n",
    "\n",
    "    Where:\n",
    "\n",
    "    * $\\nabla \\mathcal{L}(w_0)$ is the gradient vector of the loss at w_0\n",
    "    * $H$ is the Hessian matrix, i.e. $H = \\nabla^2 \\mathcal{L}(w_0)$\n",
    "\n",
    "    ---\n",
    "\n",
    "    ## 2. If the model is trained??\n",
    "\n",
    "    If the model has been well trained, then:\n",
    "\n",
    "    $\\nabla \\mathcal{L}(w_0) \\approx 0$\n",
    "\n",
    "    Because you're sitting near a (local) minimum.\n",
    "\n",
    "    This removes the linear term:\n",
    "    $\\mathcal{L}(w_0 + \\Delta w) - \\mathcal{L}(w_0) \\approx \\frac{1}{2} \\Delta w^T H \\Delta w$\n",
    "\n",
    "    So the change in loss caused by a perturbation $\\Delta w$ is approximately:\n",
    "    $\\Delta \\mathcal{L} \\approx \\frac{1}{2} \\Delta w^T H \\Delta w$\n",
    "\n",
    "    ---\n",
    "\n",
    "    ## 3. Interpretation for bit flips\n",
    "\n",
    "    A bit flip in the quantized weights causes a small but structured change in the weights:\n",
    "\n",
    "    * Say, flipping the 3rd bit in weight $w_i$ causes it to change by $\\delta_i$, so:\n",
    "\n",
    "    $\\Delta w = \\begin{bmatrix}\n",
    "    0 \\\\ \\cdots \\\\ \\delta_i \\\\ \\cdots \\\\ 0\n",
    "    \\end{bmatrix}$\n",
    "\n",
    "    Then the loss increase is (approximately):\n",
    "    $\\Delta \\mathcal{L} \\approx \\frac{1}{2} \\delta_i^2 H_{ii}$\n",
    "\n",
    "    If multiple bits are flipped across weights, you sum their pairwise interactions via H, including off-diagonal terms (if not ignored).\n",
    "\n",
    "    --- \n",
    "\n",
    "    ## 4. Implications for ranking\n",
    "\n",
    "    This approximation motivates ranking bit positions (or weights) by:\n",
    "\n",
    "    * $\\delta^2 \\cdot H_{ii}$: bit-flip magnitude times curvature\n",
    "    * This is the FKeras method: estimates $H_{ii}$ and ranks accordingly\n",
    "    * You could generalize it to your method:\n",
    "    $\\text{Impact} \\cdot H$, not just gradients\n",
    "\n",
    "    ---\n",
    "\n",
    "    ## 5. When does this approximation hold?\n",
    "\n",
    "    ?? Works well when:\n",
    "\n",
    "    * Bit-flip magnitude is small (i.e., local region)\n",
    "    * Model is near a minimum\n",
    "    * Hessian is stable (not exploding)\n",
    "\n",
    "    ?? Fails when:\n",
    "\n",
    "    * Model isn??t trained well (gradient is large)\n",
    "    * Loss surface is highly non-quadratic\n",
    "\n",
    "    ---\n",
    "\n",
    "    ## Summary\n",
    "\n",
    "    The formula:\n",
    "    $\\Delta \\mathcal{L} \\approx \\frac{1}{2} \\Delta \\mathbf{w}^T H \\Delta \\mathbf{w}$\n",
    "\n",
    "    tells us how bit-flips propagate into loss increases, and explains why the Hessian is so powerful for ranking robustness. \n",
    "    It encodes:\n",
    "\n",
    "    * How impactful a perturbation is (via $\\delta$)\n",
    "    * How sensitive the loss is locally (via $H$)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create markdown\n",
    "    md = pg.Markdown(md)\n",
    "\n",
    "    # Add to the first tab\n",
    "    tabmotivation.append(md)\n",
    "\n",
    "    \"\"\" Add quantization container to doc report \"\"\"\n",
    "    tabpretraining.extend(Q.html())\n",
    "\n",
    "    \"\"\" Save doc to file (we save after adding each element) \"\"\"\n",
    "    doc.save(filename)\n",
    "\n",
    "    # Let's create a container for all benchmarks \n",
    "    benchmark_ct = pg.CollapsibleContainer(\"üß∫ Benchmarks\", layout='vertical')\n",
    "\n",
    "    # And another one for tabtraining\n",
    "    benchmark_sessions_ct = pg.CollapsibleContainer(\"üß∫ Benchmarks\", layout='vertical')\n",
    "\n",
    "    # And another one for tabposttraining\n",
    "    benchmark_posttraining_ct = pg.CollapsibleContainer(\"üß∫ Benchmarks\", layout='vertical')\n",
    "\n",
    "    # And yet another for \"BER Injection\"\n",
    "    benchmark_ber_ct = pg.CollapsibleContainer(\"üß™ Experiments\", layout='vertical')\n",
    "\n",
    "    \"\"\" Add to documnt \"\"\"\n",
    "    tabpretraining.append(benchmark_ct)\n",
    "\n",
    "    \"\"\" Add \"\"\"\n",
    "    tabtraining.append(benchmark_sessions_ct)\n",
    "\n",
    "    \"\"\" Add \"\"\"\n",
    "    tabposttraining.append(benchmark_posttraining_ct)\n",
    "\n",
    "    \"\"\" Add \"\"\"\n",
    "    tabber.append(benchmark_ber_ct)\n",
    "\n",
    "    # Define benchmarks to analyze\n",
    "    #benchmarks = ['dummy', 'mnist_hls4ml', 'autompg', 'smartpixel_small', 'smartpixel_large',\n",
    "    #              'cifar10', 'mnist_lenet5', 'ECONT_AE'\n",
    "    # 'cifar100', 'svhn', 'fashion_mnist', 'imdb', 'reuters', 'boston_housing']\n",
    "    # TODO: Fix visualization/contrast for cifar10\n",
    "    # TODO: mnist_lenet5 seems to be working (good accuracy), but I'm not too happy about the alphas/betas. Some layers still have a big portion outside of the valid interval\n",
    "\n",
    "    config_per_methods = netsurf.config.config_per_method\n",
    "    protection_range = (0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4) #netsurf.config.DEFAULT_PROTECTION\n",
    "    ber_range = (0.001, 0.005, 0.01, 0.05, 0.1, 0.15) #netsurf.config.DEFAULT_BER\n",
    "\n",
    "    #methods = ['qpolar', 'qpolargrad', 'bitwise_msb', 'random', 'hirescam_norm', \n",
    "    #           'hiresdelta', 'hessian', 'hessiandelta', 'weight_abs_value']\n",
    "    methods = ['hessian', 'fisher', 'qpolar', 'qpolargrad', 'bitwise_msb', 'random', 'grad_norm', 'graddelta', 'weight_abs_value']\n",
    "    methods = methods\n",
    "\n",
    "    # Loop for benchmarks\n",
    "    for benchmark_name in benchmarks:\n",
    "        # Create benchmark object \n",
    "        bmk = netsurf.get_benchmark(benchmark_name, Q,  benchmarks_dir = benchmarks_dir,\n",
    "                                    datasets_dir = datasets_dir, pruning = pruning,\n",
    "                                    load_weights = False)\n",
    "        \n",
    "        # Add benchmark html to container (this includes model + dataset htmls)\n",
    "        # (run before training the model...)\n",
    "        benchmark_ct.append(bmk.html())\n",
    "\n",
    "        # Now let's prepare the data\n",
    "        nsample_mod = 48 if 'ECON' in bmk.name else -1\n",
    "        XYTrain = netsurf.utils.prepare_data(bmk, subset = 'train', nsample_mod = nsample_mod)\n",
    "\n",
    "        # Initialize the uncertainty profiler (pre-training)\n",
    "        pre_robustness_sgn_path = os.path.join(bmk.model_dir, 'uncertainty_signatures', f'{benchmark_name}.pretraining.netsurf.sgn')\n",
    "        pre_robustness_sgn = netsurf.UncertaintyProfiler.profile(bmk.model, XYTrain, bmk.model.loss, \n",
    "                                                                batch_size = 2000, filepath = pre_robustness_sgn_path,\n",
    "                                                                verbose = True)\n",
    "        # Save \n",
    "        pre_robustness_sgn.save_to_file(pre_robustness_sgn_path)\n",
    "        \n",
    "        # Add profile to tabpretraining\n",
    "        benchmark_ct.append(pre_robustness_sgn.html())\n",
    "\n",
    "        # Now we can reload the weights (After the profiling)\n",
    "        bmk.load_weights(verbose = True)\n",
    "\n",
    "        # TRAINING - SESSION\n",
    "        # Try to get a session (if not, train)\n",
    "        sess = netsurf.get_training_session(bmk, show_plots = False, plot = True)\n",
    "\n",
    "        # Create a container for this bmk in tabtraining\n",
    "        bmk_sess_ct = pg.CollapsibleContainer(benchmark_name, layout='vertical')\n",
    "\n",
    "        # Add session to tabtraining\n",
    "        bmk_sess_ct.append(sess.html())\n",
    "\n",
    "        # And add to benchmarks in tabtraining\n",
    "        benchmark_sessions_ct.append(bmk_sess_ct)\n",
    "\n",
    "        # Add benchmark again to post-training to check how the weights changed\n",
    "        benchmark_posttraining_ct.append(bmk.html())\n",
    "\n",
    "        # Initialize the uncertainty profiler (post-training)\n",
    "        post_robustness_sgn_path = os.path.join(bmk.model_dir, 'uncertainty_signatures', f'{benchmark_name}.posttraining.netsurf.sgn')\n",
    "        post_robustness_sgn = netsurf.UncertaintyProfiler.profile(bmk.model, XYTrain, bmk.model.loss, \n",
    "                                        batch_size = 2000, verbose = True, filepath = post_robustness_sgn_path)\n",
    "\n",
    "        # Save \n",
    "        post_robustness_sgn.save_to_file(post_robustness_sgn_path)\n",
    "        \n",
    "        # Add profile to tabposttraining\n",
    "        benchmark_posttraining_ct.append(post_robustness_sgn.html())\n",
    "\n",
    "        # Let's compare the divergence between the profiles\n",
    "        div_profile = netsurf.ProfileDivergence.from_signatures(pre_robustness_sgn, post_robustness_sgn)\n",
    "\n",
    "        #div_profile.plot_divergence_summary()\n",
    "        #div_profile.plot_advanced_divergence_summary()\n",
    "\n",
    "        \"\"\" Save doc to file (we save after adding each element) \"\"\"\n",
    "        doc.save(filename)\n",
    "        \n",
    "        # Create a container for this benchmark in \"BER Injection\"\n",
    "        bmk_ber_ct = pg.CollapsibleContainer(benchmark_name, layout='vertical')\n",
    "\n",
    "        # Add to tabber\n",
    "        benchmark_ber_ct.append(bmk_ber_ct)\n",
    "\n",
    "        # Create another container to store the individual results of the experiments\n",
    "        exp_individual_ct = pg.CollapsibleContainer(\"üéÅ Individual results\", layout='vertical')\n",
    "        bmk_ber_ct.append(exp_individual_ct)\n",
    "\n",
    "        # Create our ranker profiler (empty)\n",
    "        rankers_bucket = netsurf.RankingComparator()\n",
    "\n",
    "        # Loop thru methods\n",
    "        exps = {}\n",
    "        for method_alias in methods:\n",
    "            #########################################################################\n",
    "            # 0. Create the directory for the experiment (ranking, results, etc.)\n",
    "            #########################################################################\n",
    "            method = config_per_methods[method_alias]['method']\n",
    "            method_dir = os.path.join(bmk.experiments_dir, method)\n",
    "\n",
    "            #########################################################################\n",
    "            # 1. Create the ranker\n",
    "            #########################################################################\n",
    "            rkr = rankers_bucket.build_ranker(method, Q, config = config_per_methods[method], \n",
    "                                            path = method_dir,\n",
    "                                            is_baseline = (method == 'qpolargrad'))\n",
    "\n",
    "            # Get the exp dir from the ranker (with the hash)\n",
    "            exp_dir = rkr.path\n",
    "\n",
    "            #################################################################\n",
    "            # 1. Perform ranking according to method\n",
    "            #################################################################\n",
    "            # Rank weights \n",
    "            ranking = rkr.rank(bmk.model, *XYTrain, verbose = True)\n",
    "            # Save rank to csv file \n",
    "            ranking.save(overwrite = False)\n",
    "\n",
    "            #################################################################\n",
    "            # 2. Create experiment object\n",
    "            #################################################################\n",
    "            exp = netsurf.Experiment(bmk, ranking, num_reps = -1, \n",
    "                                    ber_range = ber_range, \n",
    "                                    protection_range = protection_range, \n",
    "                                    path = exp_dir,\n",
    "                                    verbose = True)\n",
    "        \n",
    "            # Print experiment info \n",
    "            print(exp)\n",
    "\n",
    "            #################################################################\n",
    "            # 3. Run experiment with given ranking and for whatever \n",
    "            #       range of protection and rad \n",
    "            #################################################################\n",
    "            #batch_size = 1000,\n",
    "            exp.run_experiment(bmk, XYTrain,\n",
    "                            batch_size = None,\n",
    "                            ber_range = ber_range, \n",
    "                            protection_range = protection_range, \n",
    "                            rerun = False)\n",
    "            \n",
    "            # Add experiment to container\n",
    "            exp_individual_ct.append(exp.html())\n",
    "\n",
    "            # Save experiment object\n",
    "            exp.save()\n",
    "\n",
    "            # Add to dict\n",
    "            exps[method] = exp\n",
    "\n",
    "            \"\"\" Save doc to file (we save after adding each element) \"\"\"\n",
    "            doc.save(filename)\n",
    "        \n",
    "        \"\"\" Now perform the comparison of rankers \"\"\"\n",
    "        df = rankers_bucket.compare_rankers(granularity = 0.01, bootstrap = False)\n",
    "        \n",
    "        # Add comparison to container\n",
    "        bmk_ber_ct.append(rankers_bucket.html())\n",
    "\n",
    "        # Save doc \n",
    "        doc.save(filename)\n",
    "\n",
    "        # Save the rankers_bucket\n",
    "        rankers_comparison_filepath = os.path.join(bmk.experiments_dir, 'ranking_comparison.csv')\n",
    "        rankers_bucket.save_to_csv(rankers_comparison_filepath)\n",
    "        \n",
    "        \"\"\" Create Experiment Comparator \"\"\"\n",
    "        exp_comp = netsurf.ExperimentComparator(list(exps.values()))\n",
    "        #df = ExperimentComparator.compute_ranking_distribution(res)\n",
    "\n",
    "        # Add html\n",
    "        bmk_ber_ct.append(exp_comp.html())\n",
    "\n",
    "        # Save doc\n",
    "        doc.save(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsbmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
