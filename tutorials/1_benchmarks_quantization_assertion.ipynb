{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Enforcement and Assertion\n",
    "We found out that qkeras does not enforce the quantization of the layers during training: it simply learns the alpha values so the activations can be later scaled down according to\n",
    "\n",
    "$y = \\alpha x + b$\n",
    "\n",
    "This forces us to make sure that we apply our quantization scheme on each layer. Thus we had to create classes for specifically enforcing the kernel/bias/activation quantization/initialization/constraint within the quantization range and limits. \n",
    "\n",
    "In this notebook we simply iterate over all pre-defined models, build them (with default shapes), and we assert whether all the weights and network parameters are within range. \n",
    "\n",
    "Then we pass some random data (normalized) and check that all the activations are also within range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /Users/mbvalentin/scripts/netsurf/dev to sys.path\n",
      "[INFO] - Added fkeras to sys.path from /Users/mbvalentin/scripts/netsurf/dev/fkeras\n",
      "[INFO] - Added qkeras to sys.path from /Users/mbvalentin/scripts/netsurf/dev/qkeras\n",
      "[INFO] - Added pergamos to sys.path from /Users/mbvalentin/scripts/netsurf/dev/pergamos\n",
      "[INFO] - Loaded theme: default\n",
      "\u001b[48;2;141;47;102m\u001b[48;2;141;47;102m \u001b[48;2;117;39;85m \u001b[48;2;94;31;68m \u001b[48;2;70;23;51m \u001b[48;2;46;15;33m \u001b[48;2;23;7;17m \u001b[48;2;0;0;0m \u001b[48;2;23;7;17m \u001b[48;2;46;15;33m \u001b[48;2;70;23;51m \u001b[48;2;94;31;68m \u001b[48;2;117;39;85m \u001b[48;2;141;47;102m      \u001b[48;2;249;230;207m â–– â–›â–›â–›â–™â– â–™    â–™â–˜ \u001b[0m\n",
      "\u001b[48;2;141;47;102m\u001b[48;2;141;47;102m \u001b[48;2;117;39;85m \u001b[48;2;94;31;68m \u001b[48;2;70;23;51mğŒ\u001b[48;2;46;15;33m \u001b[48;2;23;7;17mâ† \u001b[48;2;0;0;0mâŒ¾\u001b[48;2;23;7;17mâ†\u001b[48;2;46;15;33m \u001b[48;2;70;23;51mğŒƒ\u001b[48;2;94;31;68m \u001b[48;2;117;39;85mğŒ–\u001b[48;2;141;47;102m ğŒ”    \u001b[48;2;250;198;122m â– â––â–˜â–œâ–˜â–˜â–—  â––  â–—â–› \u001b[0m\n",
      "\u001b[48;2;141;47;102m\u001b[48;2;141;47;102m \u001b[48;2;117;39;85m \u001b[48;2;94;31;68m \u001b[48;2;70;23;51m \u001b[48;2;46;15;33m \u001b[48;2;23;7;17m \u001b[48;2;0;0;0m \u001b[48;2;23;7;17m \u001b[48;2;46;15;33m \u001b[48;2;70;23;51m \u001b[48;2;94;31;68m \u001b[48;2;117;39;85m \u001b[48;2;141;47;102m      \u001b[48;2;250;198;122m   â–šâ–™  â–œ â–™â–˜â–œ â–™ â– \u001b[0m\n",
      "\n",
      "Logging to file: /Users/mbvalentin/.nodus/nodus_20250319_002301.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- Date: 19/Mar/2025\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "â•° INFO â”€â”¤ 00:23:01.05 â”‚ - Nodus initialized\n",
      "        â”‚ 00:23:01.05 â”‚ - Nodus version: 0.1.0\n",
      "        â”‚ 00:23:01.06 â”‚ - Nodus imported\n",
      "        â”‚ 00:23:01.06 â”‚ - Jobs imported\n",
      "        â”‚ 00:23:01.06 â”‚ - JobManager imported\n",
      "        â”‚ 00:23:01.06 â”‚ - Nodus ready to use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found config file: /Users/mbvalentin/.wsbmr/config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        â”‚ 00:23:01.32 â”‚ - Created jobs table in NodusDB instance 'wsbmr_db'\n",
      "        â”‚ 00:23:01.32 â”‚ - Created job_dependencies table in NodusDB instance 'wsbmr_db'\n",
      "        â”‚ 00:23:01.32 â”‚ - Added NodusDB instance 'wsbmr_db' linked to database 'wsbmr_db'\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/Users/mbvalentin/scripts/netsurf/dev')\n",
    "sys.path = ['/Users/mbvalentin/scripts/tensorplot'] + sys.path\n",
    "import os \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Suppress unnecessary logs\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"  # Disable OneDNN optimizations\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disable GPU usage\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Limit OpenMP threads\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"1\"  # Limit inter-op parallelism\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"1\"  # Limit intra-op parallelism\n",
    "\n",
    "# Import datetime to get today's date\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\" Let's add our custom wsbmr code \"\"\"\n",
    "import wsbmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§® <QuantizationScheme(q<6,0,1>)> obj @ (0x1059af730):\n",
      "    Total number of bits (m): 6\n",
      "    Integer bits         (n): 0\n",
      "    Float bits           (f): 5\n",
      "    Signed\n",
      "    Range: (-1, 0.96875)\n",
      "    Min step: 0.03125\n",
      "    Format: S.xxxxx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize a pergamos document for our output report \"\"\"\n",
    "import pergamos as pg\n",
    "\n",
    "# Set variables\n",
    "qscheme = \"q<6,0,1>\"\n",
    "\"\"\" First of all, let's define a quantization Scheme \"\"\"\n",
    "Q = wsbmr.QuantizationScheme(qscheme)\n",
    "print(Q)\n",
    "#benchmarks = ['mnist_fnn', 'autompg', 'smartpixel_small']\n",
    "benchmarks = ['mnist_hls4ml']\n",
    "\n",
    "# Set filename\n",
    "\n",
    "filename = f\"2_qpolar_{Q._scheme_str.no_special_chars()}_bmarks_{'_'.join(benchmarks)}.html\"\n",
    "doc = pg.Document(filename, theme=\"default\")\n",
    "\n",
    "\"\"\" Add a title to the document \"\"\"\n",
    "doc.append(pg.Markdown(f\"\"\"# Benchmarks Quantization Assertion\n",
    "> Author: Manuel B Valentin\n",
    "\n",
    "> Creation date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "> Project: wsbmr/netsurf\n",
    "\n",
    "> Used packages: wsbmr, tensorflow, numpy, matplotlib, pergamos\n",
    "        \n",
    "\"\"\"))\n",
    "\n",
    "# Add a tab container\n",
    "tabs = pg.TabbedContainer({'Motivation': [], \n",
    "                           'Pre-training analysis': [],\n",
    "                           'Training': [],\n",
    "                            'Post-Training': [],\n",
    "                           'BER Injection': [],\n",
    "                           'Conclusions': []})\n",
    "\n",
    "# Get individual tabs\n",
    "tabmotivation = tabs['Motivation']\n",
    "tabpretraining = tabs['Pre-training analysis']\n",
    "tabtraining = tabs['Training']\n",
    "tabposttraining = tabs['Post-Training']\n",
    "tabber = tabs['BER Injection']\n",
    "tabconclusions = tabs['Conclusions']\n",
    "\n",
    "# Add to documnt\n",
    "doc.append(tabs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a markdown description of what we want to achieve with this report in the first tab\n",
    "md = f\"\"\"\n",
    "This report aims to assert the quantization of the benchmarks used in the wsbmr project.\n",
    "The motivation for this is to ensure that the models are quantized correctly and that the quantization is applied as expected, since \n",
    "we realized that the activations at the outputs of the layers are NOT quantized as expected. They are, in fact, \n",
    "floating point numbers and most of the time, they are not even in the range of the quantization. This is because\n",
    "`qkeras` does NOT enforce the quantization of the activations at the output of the layers. \n",
    "\n",
    "### What does qkeras do then?\n",
    "`qkeras` keeps track of the quantization parameters of the layers and while training the network, it learns the `alpha` values,\n",
    "which are nothing but values that will be used to scale the activations at the output of the layers. This is done to ensure that the\n",
    "activations are in the range of the quantization. However, this is not enforced and the activations can still be floating point numbers.\n",
    "\n",
    "### Why is this a problem for us in the wsbmr/netsurf project?\n",
    "Because when we inject the bit-flip errors using our deltas, we are still dealing with floating point numbers and not with quantized numbers.\n",
    "This means that the bit-flip errors are not being injected correctly and the results are not as expected. In fact, we expect the results to be \n",
    "worse than what we are seeing, because the bit-flip errors will have a bigger effect on the quantized numbers than on the floating point numbers.\n",
    "This is because the floating point numbers that we are seeing in our results are normally OUTSIDE of the range of the quantization (and thus,\n",
    "of the range of the bit-flip errors).\n",
    "\n",
    "### How is this report structured?\n",
    "This report is structured in the following way:\n",
    "\n",
    "1. The first tab contains this markdown with the motivation for this report.\n",
    "2. In the first tab (Initial state) we will show:\n",
    "    1. The quantization scheme we are using. \n",
    "    2. Each one of the models that we are using, for which we show:\n",
    "        1. The model summary with shapes, optimizers, parameters, etc.\n",
    "        2. The loss and metrics functions definitions.\n",
    "        3. All the layers of the model one-by-one. For each layer we'll show:\n",
    "            1. The layer properties (name, type, shape, etc.)\n",
    "            2. The quantization of the layer. \n",
    "            3. The range of values we expect (for weights, biases, etc.)\n",
    "            4. The ACTUAL values for the layers parameters (weights, biases, etc.)\n",
    "            5. An histogram with the ACTUAL values for these params.\n",
    "    3. A plot with the architecture of the model.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create markdown\n",
    "md = pg.Markdown(md)\n",
    "\n",
    "# Add to the first tab\n",
    "tabmotivation.append(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Add quantization container to doc report \"\"\"\n",
    "tabpretraining.extend(Q.html())\n",
    "\n",
    "\"\"\" Save doc to file (we save after adding each element) \"\"\"\n",
    "doc.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° BMK â”€â”€â”¤ 00:23:02.90 â”‚ - Initializing benchmark object mnist_hls4ml\n",
      "        â”‚ 00:23:02.90 â”‚ - Loss categorical_crossentropy found in tf.keras.losses with definition <function categorical_crossentropy at 0x16a2ae830>.\n",
      "        â”‚ 00:23:02.90 â”‚ - Adding custom metric categorical_accuracy with definition CategoricalAccuracy(name=categorical_accuracy,dtype=float32).\n",
      "        â”‚ 00:23:06.16 â”‚ - Saving benchmark metadata to file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/.metadata.wsbmr\n",
      "        â”‚ 00:23:06.16 â”‚ - Saving quantization metadata to file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/.metadata.wsbmr\n",
      "        â”‚ 00:23:06.16 â”‚ - Saving model metadata to file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/.metadata.wsbmr\n",
      "        â”‚ 00:23:06.16 â”‚ - No path provided, looking for latest h5 file at default model path: /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/models\n",
      "        â”‚ 00:23:06.16 â”‚ - Looking for file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/models/72591_hls4ml_cnn.keras.latest\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° WARN â”€â”¤ 00:23:06.16 â”‚ - Weights file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/models/72591_hls4ml_cnn.keras.latest not found\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° BMK â”€â”€â”¤ 00:23:06.16 â”‚ - Benchmark object mnist_hls4ml initialized\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° DATA â”€â”¤ 00:23:06.38 â”‚ - Normalizing dataset (input) using quantizer range (-1, 0.96875)\n",
      "/Users/mbvalentin/scripts/netsurf/dev/wsbmr/utils/plot.py:601: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared.\n",
      "  pts = pd.DataFrame(shapes).T.plot.pie(ax = ax, subplots = True)\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° PLOT â”€â”¤ 00:23:12.84 â”‚ - Saved figure to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/models/weights_pie.png\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° WARN â”€â”¤ 00:24:00.82 â”‚ - No session files found at /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/sessions\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° MDL â”€â”€â”¤ 00:24:00.82 â”‚ - Running session with batch_size = 40, epochs = 10, opt_params = {'learning_rate': 0.001}, pruning_params = {}\n",
      "        â”‚ 00:24:00.82 â”‚ - Compiling model with parameters learning_rate=0.001\n",
      "        â”‚ 00:24:00.82 â”‚ - Fitting model with 10 epochs and batch_size 40\n",
      "        â”‚ 00:24:39.77 â”‚ - Epoch 0 - {'loss': 3.467036247253418, 'categorical_accuracy': 0.46568334102630615, 'val_loss': 1.6525310277938843, 'val_categorical_accuracy': 0.6794000267982483, 'lr': 0.001}\n",
      "        â”‚ 00:24:39.77 â”‚ - Epoch 0 - {'loss': 3.467036247253418, 'categorical_accuracy': 0.46568334102630615, 'val_loss': 1.6525310277938843, 'val_categorical_accuracy': 0.6794000267982483, 'lr': 0.001}\n",
      "        â”‚ 00:25:20.21 â”‚ - Epoch 1 - {'loss': 1.3648043870925903, 'categorical_accuracy': 0.7411333322525024, 'val_loss': 1.1726279258728027, 'val_categorical_accuracy': 0.7839000225067139, 'lr': 0.001}\n",
      "        â”‚ 00:25:20.21 â”‚ - Epoch 1 - {'loss': 1.3648043870925903, 'categorical_accuracy': 0.7411333322525024, 'val_loss': 1.1726279258728027, 'val_categorical_accuracy': 0.7839000225067139, 'lr': 0.001}\n",
      "        â”‚ 00:26:01.51 â”‚ - Epoch 2 - {'loss': 0.9795670509338379, 'categorical_accuracy': 0.8448333144187927, 'val_loss': 0.8638701438903809, 'val_categorical_accuracy': 0.8720999956130981, 'lr': 0.001}\n",
      "        â”‚ 00:26:01.51 â”‚ - Epoch 2 - {'loss': 0.9795670509338379, 'categorical_accuracy': 0.8448333144187927, 'val_loss': 0.8638701438903809, 'val_categorical_accuracy': 0.8720999956130981, 'lr': 0.001}\n",
      "        â”‚ 00:26:43.78 â”‚ - Epoch 3 - {'loss': 0.8101528286933899, 'categorical_accuracy': 0.8867666721343994, 'val_loss': 0.7314843535423279, 'val_categorical_accuracy': 0.9075999855995178, 'lr': 0.001}\n",
      "        â”‚ 00:26:43.78 â”‚ - Epoch 3 - {'loss': 0.8101528286933899, 'categorical_accuracy': 0.8867666721343994, 'val_loss': 0.7314843535423279, 'val_categorical_accuracy': 0.9075999855995178, 'lr': 0.001}\n",
      "        â”‚ 00:27:24.14 â”‚ - Epoch 4 - {'loss': 0.7032464742660522, 'categorical_accuracy': 0.9125999808311462, 'val_loss': 0.6452844738960266, 'val_categorical_accuracy': 0.9239000082015991, 'lr': 0.001}\n",
      "        â”‚ 00:27:24.14 â”‚ - Epoch 4 - {'loss': 0.7032464742660522, 'categorical_accuracy': 0.9125999808311462, 'val_loss': 0.6452844738960266, 'val_categorical_accuracy': 0.9239000082015991, 'lr': 0.001}\n",
      "        â”‚ 00:27:56.90 â”‚ - Epoch 5 - {'loss': 0.6294878721237183, 'categorical_accuracy': 0.9263333082199097, 'val_loss': 0.5623684525489807, 'val_categorical_accuracy': 0.9417999982833862, 'lr': 0.001}\n",
      "        â”‚ 00:27:56.90 â”‚ - Epoch 5 - {'loss': 0.6294878721237183, 'categorical_accuracy': 0.9263333082199097, 'val_loss': 0.5623684525489807, 'val_categorical_accuracy': 0.9417999982833862, 'lr': 0.001}\n",
      "        â”‚ 00:28:33.35 â”‚ - Epoch 6 - {'loss': 0.5715332627296448, 'categorical_accuracy': 0.9367499947547913, 'val_loss': 0.5771080255508423, 'val_categorical_accuracy': 0.930899977684021, 'lr': 0.001}\n",
      "        â”‚ 00:28:33.35 â”‚ - Epoch 6 - {'loss': 0.5715332627296448, 'categorical_accuracy': 0.9367499947547913, 'val_loss': 0.5771080255508423, 'val_categorical_accuracy': 0.930899977684021, 'lr': 0.001}\n",
      "        â”‚ 00:29:09.19 â”‚ - Epoch 7 - {'loss': 0.52419513463974, 'categorical_accuracy': 0.944016695022583, 'val_loss': 0.531348705291748, 'val_categorical_accuracy': 0.9404000043869019, 'lr': 0.001}\n",
      "        â”‚ 00:29:09.20 â”‚ - Epoch 7 - {'loss': 0.52419513463974, 'categorical_accuracy': 0.944016695022583, 'val_loss': 0.531348705291748, 'val_categorical_accuracy': 0.9404000043869019, 'lr': 0.001}\n",
      "        â”‚ 00:29:48.57 â”‚ - Epoch 8 - {'loss': 0.48671507835388184, 'categorical_accuracy': 0.9497666954994202, 'val_loss': 0.45005956292152405, 'val_categorical_accuracy': 0.9592999815940857, 'lr': 0.001}\n",
      "        â”‚ 00:29:48.57 â”‚ - Epoch 8 - {'loss': 0.48671507835388184, 'categorical_accuracy': 0.9497666954994202, 'val_loss': 0.45005956292152405, 'val_categorical_accuracy': 0.9592999815940857, 'lr': 0.001}\n",
      "        â”‚ 00:30:29.29 â”‚ - Epoch 9 - {'loss': 0.45283567905426025, 'categorical_accuracy': 0.9538499712944031, 'val_loss': 0.4876784086227417, 'val_categorical_accuracy': 0.9402999877929688, 'lr': 0.001}\n",
      "        â”‚ 00:30:29.29 â”‚ - Epoch 9 - {'loss': 0.45283567905426025, 'categorical_accuracy': 0.9538499712944031, 'val_loss': 0.4876784086227417, 'val_categorical_accuracy': 0.9402999877929688, 'lr': 0.001}\n",
      "        â”‚ 00:30:29.29 â”‚ - Model fitted in 388.47 seconds after 10 epochs\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° BMK â”€â”€â”¤ 00:30:29.45 â”‚ - Session saved to file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/sessions/training_session.20250319_002400/training_session.20250319_002400.pkl\n",
      "        â”‚ 00:30:29.45 â”‚ - Config saved to file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/sessions/training_session.20250319_002400/config_training_session.20250319_002400.json\n",
      "        â”‚ 00:30:29.52 â”‚ - Weights saved to h5 file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/models/72591_hls4ml_cnn.20250319_003029.weights.h5\n",
      "        â”‚ 00:30:29.58 â”‚ - Model saved to keras file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/models/72591_hls4ml_cnn.20250319_003029.keras\n",
      "        â”‚ 00:30:29.58 â”‚ - Created a symlink to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/models/72591_hls4ml_cnn.weights.h5.latest\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° PLOT â”€â”¤ 00:30:30.82 â”‚ - Saved training history plot to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/sessions/training_session.20250319_002400/training_session.20250319_002400_training_history.png\n",
      "/Users/mbvalentin/scripts/netsurf/dev/wsbmr/utils/plot.py:601: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared.\n",
      "  pts = pd.DataFrame(shapes).T.plot.pie(ax = ax, subplots = True)\n",
      "        â”‚ 00:30:30.99 â”‚ - Saved figure to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/models/weights_pie.png\n",
      "        â”‚ 00:30:31.02 â”‚ - Variable qq_dense_1/kernel_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.02 â”‚ - Variable qq_dense_1/kernel_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.03 â”‚ - Variable qq_dense/kernel_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.03 â”‚ - Variable qq_dense/kernel_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.04 â”‚ - Variable qq_dense_2/kernel_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.04 â”‚ - Variable qq_dense_2/kernel_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.04 â”‚ - Variable qq_conv2d_2/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.05 â”‚ - Variable qq_dense_1/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.05 â”‚ - Variable qq_conv2d_1/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.06 â”‚ - Variable qq_dense/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.06 â”‚ - Variable qq_dense_2/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.06 â”‚ - Variable qq_dense_1/bias_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.06 â”‚ - Variable qq_dense_1/bias_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.07 â”‚ - Variable qq_dense/bias_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.07 â”‚ - Variable qq_dense/bias_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.08 â”‚ - Variable qq_conv2d/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.08 â”‚ - Variable qq_dense_1/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.08 â”‚ - Variable qq_dense_2/bias_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.08 â”‚ - Variable qq_dense_2/bias_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.09 â”‚ - Variable qq_dense/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.09 â”‚ - Variable qq_conv2d_2/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.10 â”‚ - Variable qq_conv2d_1/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.10 â”‚ - Variable qq_conv2d/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.10 â”‚ - Variable qq_dense_2/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.34 â”‚ - Saved sparsity plot to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/sessions/training_session.20250319_002400/sparsity.png\n",
      "        â”‚ 00:30:31.34 â”‚ - Plot range is -1.068572759628296 to 0.9504086375236511\n",
      "        â”‚ 00:30:31.38 â”‚ - Variable qq_conv2d/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.38 â”‚ - Variable qq_conv2d/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.39 â”‚ - Variable qq_conv2d_1/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.39 â”‚ - Variable qq_conv2d_1/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.39 â”‚ - Variable qq_conv2d_2/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.40 â”‚ - Variable qq_conv2d_2/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.40 â”‚ - Variable qq_dense/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.40 â”‚ - Variable qq_dense/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.41 â”‚ - Variable qq_dense/kernel_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.41 â”‚ - Variable qq_dense/kernel_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.42 â”‚ - Variable qq_dense/bias_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.42 â”‚ - Variable qq_dense/bias_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.42 â”‚ - Variable qq_dense_1/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.43 â”‚ - Variable qq_dense_1/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.43 â”‚ - Variable qq_dense_1/kernel_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.44 â”‚ - Variable qq_dense_1/kernel_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.44 â”‚ - Variable qq_dense_1/bias_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.45 â”‚ - Variable qq_dense_1/bias_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.45 â”‚ - Variable qq_dense_2/kernel:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.45 â”‚ - Variable qq_dense_2/bias:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.46 â”‚ - Variable qq_dense_2/kernel_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.46 â”‚ - Variable qq_dense_2/kernel_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:31.46 â”‚ - Variable qq_dense_2/bias_delta:0 has sparsity 0.00%\n",
      "        â”‚ 00:30:31.46 â”‚ - Variable qq_dense_2/bias_N:0 has sparsity 100.00%\n",
      "        â”‚ 00:30:32.50 â”‚ - Saved sparsity plot to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/sessions/training_session.20250319_002400/sparsity_separated.png\n",
      "        â”‚ 00:30:32.51 â”‚ - Plot range is -1.068572759628296 to 0.9504086375236511\n",
      "        â”‚ 00:30:40.45 â”‚ - QKeras accuracy = 94.00%\n",
      "        â”‚ 00:30:40.71 â”‚ - Saved ROC plot to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/sessions/training_session.20250319_002400/ROC.png\n",
      "        â”‚ 00:30:40.71 â”‚ - Plotting confusion matrix for labels ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "        â”‚ 00:30:40.82 â”‚ - Saved confusion matrix to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/sessions/training_session.20250319_002400/confusion_matrix.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+--------------------------------------------------------------------------------+\n",
      "| METHOD: qpolar                                                                 |\n",
      "| Experiment: config1                                                            |\n",
      "+--------------------------------------------------------------------------------+\n",
      "| reload_ranking: False                                                          |\n",
      "| reloaded: False                                                                |\n",
      "+--------------------------------------------------------------------------------+\n",
      "| Config:                                                                        |\n",
      "+--------------------------------------------------------------------------------+\n",
      "|     method_suffix: None                                                        |\n",
      "|     method_kws: ascending=False batch_size=96                                  |\n",
      "|     normalize: True                                                            |\n",
      "|     alias: qpolar_q<6,0,1>_normalized                                          |\n",
      "+--------------------------------------------------------------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â•° INFO â”€â”¤ 00:31:25.99 â”‚ - Creating new experiment directory with hash 158462dbf8610aa5c147b6b8da353caf @ /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/experiments/QPolar/config1\n",
      "        â”‚ 00:31:25.99 â”‚ - Saving method metadata to file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/experiments/QPolar/.metadata.wsbmr\n",
      "        â”‚ 00:31:25.99 â”‚ - Saving experiment metadata to file /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/experiments/QPolar/config1/.metadata.wsbmr\n",
      "        â”‚ 00:31:26.04 â”‚ - No results found for experiment config1\n",
      "        â”‚ 00:31:26.04 â”‚ - No ranking found for experiment config1\n",
      "        â”‚ 00:31:26.04 â”‚ - Saved configuration to /Users/mbvalentin/scripts/netsurf/benchmarks/mnist_hls4ml/q6_0_1/72591_hls4ml_cnn/experiments/QPolar/config1/config.json\n",
      "        â”‚ 00:31:26.04 â”‚ - No metrics found for experiment config1\n",
      "        â”‚ 00:31:26.04 â”‚ - Ranking weights with method qpolar... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing impact for qq_conv2d/kernel:0 - Batch 0/59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        â”‚ 00:36:49.34 â”‚ - Stats for maximum attack (N=1) for QModel for input data X ((60000, 28, 28, 1)):\n",
      "        â”‚ 00:36:49.38 â”‚ - Loss (corrupted): [2.269046  2.411766  2.1980598 ... 2.269046  2.1357584 2.4561567]\n",
      "        â”‚ 00:36:49.38 â”‚ - Loss (uncorrupted): [0.6576194  0.00334572 0.06897205 ... 0.00146854 0.00315813 0.05720679]\n",
      "        â”‚ 00:36:49.38 â”‚ - Delta loss: [1.6114266 2.4084203 2.1290877 ... 2.2675774 2.1326003 2.3989499]\n",
      "        â”‚ 00:36:49.46 â”‚ - categorical_accuracy (corrupted): 0.10441666841506958\n",
      "        â”‚ 00:36:49.47 â”‚ - categorical_accuracy (uncorrupted): 0.9390333294868469\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (3,3,1,16,6) doesn't match the broadcast shape (28,28,3,3,1,16,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 108\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(exp)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#################################################################\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# 2. Perform ranking according to method\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m#################################################################\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Rank weights \u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbmk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mXYTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Save rank to csv file \u001b[39;00m\n\u001b[1;32m    111\u001b[0m exp\u001b[38;5;241m.\u001b[39msave_ranking(df, overwrite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/scripts/netsurf/dev/wsbmr/core/experiments.py:731\u001b[0m, in \u001b[0;36mExperiment.rank\u001b[0;34m(self, model, verbose, *args, **kws)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranking \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# Rank weights and get table back\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# Keep track of how long it takes for this ranker to rank the weights\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose: wsbmr\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39m_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRanking weights with method \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranking_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m... \u001b[39m\u001b[38;5;124m'\u001b[39m, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 731\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# Check if rank returned two or one values\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n",
      "File \u001b[0;32m~/scripts/netsurf/dev/wsbmr/core/ranking.py:2180\u001b[0m, in \u001b[0;36mQPolarWeightRanker.rank\u001b[0;34m(self, model, X, Y, ascending, **kwargs)\u001b[0m\n\u001b[1;32m   2177\u001b[0m model\u001b[38;5;241m.\u001b[39mcompute_deltas()\n\u001b[1;32m   2179\u001b[0m \u001b[38;5;66;03m# Call super method to obtain DF \u001b[39;00m\n\u001b[0;32m-> 2180\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_weight_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;66;03m# Finally, sort by susceptibility \u001b[39;00m\n\u001b[1;32m   2183\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbit\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msusceptibility\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m, ascending])\n",
      "File \u001b[0;32m~/scripts/netsurf/dev/wsbmr/core/ranking.py:1948\u001b[0m, in \u001b[0;36mQPolarWeightRanker.extract_weight_table\u001b[0;34m(self, model, X, Y, quantization, ascending, verbose, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m   1945\u001b[0m     impact \u001b[38;5;241m=\u001b[39m actb\u001b[38;5;241m*\u001b[39mdelta\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;66;03m# Average per batch\u001b[39;00m\n\u001b[0;32m-> 1948\u001b[0m     subimpact \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(impact, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;66;03m# Average out\u001b[39;00m\n\u001b[1;32m   1951\u001b[0m subimpact \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (num_batches\u001b[38;5;241m*\u001b[39mbatch_size)\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (3,3,1,16,6) doesn't match the broadcast shape (28,28,3,3,1,16,6)"
     ]
    }
   ],
   "source": [
    "# Let's create a container for all benchmarks \n",
    "benchmark_ct = pg.CollapsibleContainer(\"ğŸ§º Benchmarks\", layout='vertical')\n",
    "\n",
    "# And another one for tabtraining\n",
    "benchmark_sessions_ct = pg.CollapsibleContainer(\"ğŸ§º Benchmarks\", layout='vertical')\n",
    "\n",
    "# And another one for tabposttraining\n",
    "benchmark_posttraining_ct = pg.CollapsibleContainer(\"ğŸ§º Benchmarks\", layout='vertical')\n",
    "\n",
    "# And yet another for \"BER Injection\"\n",
    "benchmark_ber_ct = pg.CollapsibleContainer(\"ğŸ§º Benchmarks\", layout='vertical')\n",
    "\n",
    "\"\"\" Add to documnt \"\"\"\n",
    "tabpretraining.append(benchmark_ct)\n",
    "\n",
    "\"\"\" Add \"\"\"\n",
    "tabtraining.append(benchmark_sessions_ct)\n",
    "\n",
    "\"\"\" Add \"\"\"\n",
    "tabposttraining.append(benchmark_posttraining_ct)\n",
    "\n",
    "\"\"\" Add \"\"\"\n",
    "tabber.append(benchmark_ber_ct)\n",
    "\n",
    "# Define benchmarks to analyze\n",
    "#benchmarks = ['dummy', 'mnist_hls4ml', 'autompg', 'smartpixel_small', 'smartpixel_large',\n",
    "#              'cifar10', 'mnist_lenet5', 'ECONT_AE'\n",
    "# 'cifar100', 'svhn', 'fashion_mnist', 'imdb', 'reuters', 'boston_housing']\n",
    "#benchmarks = ['dummy']\n",
    "# TODO: Fix visualization/contrast for cifar10\n",
    "# TODO: mnist_lenet5 seems to be working (good accuracy), but I'm not too happy about the alphas/betas. Some layers still have a big portion outside of the valid interval\n",
    "\n",
    "config_per_methods = wsbmr.config.config_per_method\n",
    "protection_range = wsbmr.config.DEFAULT_PROTECTION\n",
    "ber_range = wsbmr.config.DEFAULT_BER\n",
    "\n",
    "methods = ['qpolar', 'qpolargrad', 'bitwise_msb', 'random', 'hirescam_norm', \n",
    "           'hiresdelta', 'hessian', 'hessiandelta', 'weight_abs_value']\n",
    "\n",
    "# Loop for benchmarks\n",
    "for benchmark_name in benchmarks:\n",
    "    # Create benchmark object \n",
    "    bmk = wsbmr.get_benchmark(benchmark_name, Q, \n",
    "                    benchmarks_dir = '/Users/mbvalentin/scripts/netsurf/benchmarks',\n",
    "                    datasets_dir = '/Users/mbvalentin/scripts/netsurf/datasets')\n",
    "    \n",
    "    # Add benchmark html to container (this includes model + dataset htmls)\n",
    "    # (run before training the model...)\n",
    "    bmk.assert_dataset_is_loaded()\n",
    "    benchmark_ct.append(bmk.html())\n",
    "\n",
    "    # TRAINING - SESSION\n",
    "    # Try to get a session (if not, train)\n",
    "    sess = wsbmr.get_training_session(bmk, prune = 0.0, show_plots = False, plot = True)\n",
    "\n",
    "    # Create a container for this bmk in tabtraining\n",
    "    bmk_sess_ct = pg.CollapsibleContainer(benchmark_name, layout='vertical')\n",
    "\n",
    "    # Add session to tabtraining\n",
    "    bmk_sess_ct.append(sess.html())\n",
    "\n",
    "    # And add to benchmarks in tabtraining\n",
    "    benchmark_sessions_ct.append(bmk_sess_ct)\n",
    "\n",
    "    # Add benchmark again to post-training to check how the weights changed\n",
    "    benchmark_posttraining_ct.append(bmk.html())\n",
    "\n",
    "    # Now let's prepare the data\n",
    "    nsample_mod = 48 if 'ECON' in bmk.name else -1\n",
    "    XYTrain = wsbmr.utils.prepare_data(bmk, subset = 'train', nsample_mod = nsample_mod)\n",
    "\n",
    "    # Create a container for this benchmark in \"BER Injection\"\n",
    "    bmk_ber_ct = pg.CollapsibleContainer(benchmark_name, layout='vertical')\n",
    "\n",
    "    # Add to tabber\n",
    "    benchmark_ber_ct.append(bmk_ber_ct)\n",
    "    \n",
    "    # Loop thru methods\n",
    "    exps = {}\n",
    "    for method in methods:\n",
    "\n",
    "        # get config\n",
    "        c = {kw: kv for kw,kv in config_per_methods[method].items()}\n",
    "        method = c.pop('method')\n",
    "\n",
    "        #################################################################\n",
    "        # 1. Initialize experiment object\n",
    "        #################################################################\n",
    "        # Extend config dict\n",
    "        c_ext = dict(**c, **{'normalize': True})\n",
    "\n",
    "        # Get kws from config\n",
    "        kws = c.pop('kws') if 'kws' in c else {}\n",
    "\n",
    "        #################################################################\n",
    "        # 1. Create experiment object\n",
    "        #################################################################\n",
    "        exp = wsbmr.Experiment(method, bmk, Q, c_ext, reload_ranking = False, verbose = True,\n",
    "                               num_reps = -1, ber_range = ber_range, protection_range = protection_range, **kws)\n",
    "    \n",
    "        # Print experiment info \n",
    "        print(exp)\n",
    "\n",
    "        #################################################################\n",
    "        # 2. Perform ranking according to method\n",
    "        #################################################################\n",
    "        # Rank weights \n",
    "        df = exp.rank(bmk.model, *XYTrain, verbose = True, **kws)\n",
    "\n",
    "        # Save rank to csv file \n",
    "        exp.save_ranking(df, overwrite = False)\n",
    "\n",
    "        # Plot ranking \n",
    "        exp.ranker.plot_ranking()\n",
    "\n",
    "        #################################################################\n",
    "        # 3. Run experiment with given ranking and for whatever \n",
    "        #       range of protection and rad \n",
    "        #################################################################\n",
    "        #batch_size = 1000,\n",
    "        exp.run_experiment(bmk, \n",
    "                           batch_size = None,\n",
    "                           ber_range = ber_range, \n",
    "                           protection_range = protection_range, \n",
    "                           rerun = False)\n",
    "        \n",
    "        # Add experiment to container\n",
    "        bmk_ber_ct.append(exp.html())\n",
    "\n",
    "        # Save experiment object\n",
    "        if True:\n",
    "            exp.save()\n",
    "\n",
    "        # Add to dict\n",
    "        exps[method] = exp\n",
    "\n",
    "        \"\"\" Save doc to file (we save after adding each element) \"\"\"\n",
    "        doc.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wsbmr.gui.plotter import *\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_barplot(subplotters, \n",
    "                 ax = None, y = 'mean', metric = None,  \n",
    "                 ylims = None, title = None, xlog = False, ylog = False,\n",
    "                 show = False, info_label = None, standalone = True, \n",
    "                 baseline = None, remove_baseline = False, single_out = 'random', \n",
    "                 cmap = 'viridis', filename = None, ylabel = None,\n",
    "                 **kwargs):\n",
    "\n",
    "    # Loop thru each plotter and get the VUSs\n",
    "    VUCs = []\n",
    "    for method in subplotters:\n",
    "        # Loop thru configs \n",
    "        for config in subplotters[method]:\n",
    "            # Get the plotter obj\n",
    "            plotter = subplotters[method][config]\n",
    "            # Get the vuc\n",
    "            VUCs += [{'method': method, 'config': config, 'vus': plotter.vus.loc['vus'][y]}]\n",
    "\n",
    "    # Convert VUCs to a dataframe\n",
    "    df = pd.DataFrame(VUCs)\n",
    "    # Sort by vus \n",
    "    df = df.sort_values('vus', ascending = metric.lower() not in ['accuracy', 'acc'])\n",
    "\n",
    "    # if remove_baseline\n",
    "    if remove_baseline:\n",
    "        if baseline in df['method'].values:\n",
    "            # subtract the baseline from the vus\n",
    "            df['vus'] = df['vus'] - df[df['method'] == baseline]['vus'].values[0]\n",
    "\n",
    "    # Xrange is always the number of methods\n",
    "    # ylims\n",
    "    if ylims is None:\n",
    "        ylims = (0, 1.1*df['vus'].max())\n",
    "\n",
    "    # Create color mapper \n",
    "    # Get the min and max values\n",
    "    vmin = df['vus'].min()\n",
    "    vmax = df['vus'].max()\n",
    "    # Create a color palette\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    # Normalize the values\n",
    "    norm = plt.Normalize(vmin, vmax)\n",
    "    # Create lambda function to map any value to color later \n",
    "    color_mapper = lambda x: cmap(norm(x))\n",
    "    hatch_styles = {'auc': '**', 'vus': '//'}\n",
    "\n",
    "    # If ax is none, create a new figure\n",
    "    if ax is None or standalone:\n",
    "        fig, ax = plt.subplots()\n",
    "        wsbmr.utils.mark_figure_as_deletable(fig)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    \n",
    "    # Initialize the width, x of the bar\n",
    "    bar_w = 0.4\n",
    "    bar_space = 0.1 # Space between method bars (same method are not spaced)\n",
    "\n",
    "    \"\"\" Pyplot configuration for hatches \"\"\"\n",
    "    # Store old value of 'hatc.linewidth'\n",
    "    old_linewidth = plt.rcParams['hatch.linewidth']\n",
    "    # Set the linewidth of the hatch lines\n",
    "    plt.rcParams['hatch.linewidth'] = 0.3\n",
    "    plt.rcParams[\"lines.solid_capstyle\"] = \"butt\"\n",
    "    old_grid_color = plt.rcParams['grid.color']\n",
    "    plt.rcParams['grid.color'] = (0.5, 0.5, 0.5, 0.3)\n",
    "\n",
    "    # Group by method \n",
    "    g = df.groupby('method', sort = False)\n",
    "\n",
    "    # Set ylims \n",
    "    ax.set_ylim(ylims)\n",
    "    # Set ticks params here (we need them to get the size of the xticklabels)\n",
    "    ax.tick_params(axis='x', labelsize=9) \n",
    "\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "\n",
    "    # Find the position of the corresponding xtick label\n",
    "    label = ax.get_xticklabels()[0]  # Get the Text object for the label\n",
    "\n",
    "    # Use `get_window_extent` to find the label's extent in display space (optional)\n",
    "    renderer = fig.canvas.get_renderer()\n",
    "    bbox = label.get_window_extent(renderer=renderer)\n",
    "\n",
    "    # Convert the bounding box to data coordinates\n",
    "    inv = ax.transData.inverted()\n",
    "    bbox_data = inv.transform(bbox)\n",
    "\n",
    "    # Use the bottom of the bbox as the y-coordinate for the line\n",
    "    label_y_offset = bbox_data[1][1]  # The top edge of the label in data coordinates\n",
    "    label_new_line_height = bbox_data[1][1] - bbox_data[0][1]  # The height of the label in data coordinates\n",
    "\n",
    "    # Now loop thru methods\n",
    "    bars = []\n",
    "    for i, (method, group) in enumerate(g):\n",
    "        # Loop thru configs, vus\n",
    "        nconfigs = len(group)\n",
    "        for j, (config, vus) in enumerate(zip(group['config'], group['vus'])):\n",
    "            # Get the x position of the bar\n",
    "            x = i*(bar_w + bar_space) + j*bar_w\n",
    "            \n",
    "            # Now get all four coordinates, for simplicity \n",
    "            x0, x1, y0, y1 = x, x + bar_w, 0, vus\n",
    "\n",
    "            # Get this bar's value\n",
    "            c = color_mapper(y1)\n",
    "            hs = hatch_styles['vus']\n",
    "            if single_out is not None:\n",
    "                if single_out == method:\n",
    "                    #c = (1, 1, 1, 1) if btype == 'AUC' else (0, 0, 0, 1)\n",
    "                    c = (0, 0, 0, 1)\n",
    "                    hs = 'o'\n",
    "\n",
    "            # Add rectangle (we will delete the old bar)\n",
    "            bar = ax.fill_between([x0, x1], y0, y1, color=c[:-1] + (0.3,), edgecolor = 'k', linewidth = 0.5, label = method)\n",
    "            # Add hatch to this patch we just created \n",
    "            bar.set_hatch(hs)\n",
    "            bars.append(bar)\n",
    "\n",
    "            # Add a label on top of the bar with the value of the VUS\n",
    "            ax.text(x + bar_w/2, vus + label_new_line_height/2, f'{vus:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "            # Add xlabel to list \n",
    "            xticks += [x + bar_w/2]\n",
    "            sp = \"\".join(['\\n']*((i+j)%2))\n",
    "            mstr = method.replace('_', '\\n').replace(' ', '\\n')\n",
    "            mstr = mstr.replace('delta', r'$\\Delta$')\n",
    "            xticklabels += [f'{sp}{mstr}\\n{config}' if nconfigs > 1 else f'{sp}{mstr}']\n",
    "\n",
    "            # Add a line to connect the bar to the xticklabel underneath (only if i+j is odd)\n",
    "            if (i+j) % 2 == 1:\n",
    "                line = mlines.Line2D(\n",
    "                    [x + bar_w/2, x + bar_w/2],           # x-coordinates\n",
    "                    [0, label_y_offset - label_new_line_height*0.7],        # y-coordinates (outside the plot area)\n",
    "                    color=\"black\",\n",
    "                    lw=0.8\n",
    "                )\n",
    "                line.set_clip_on(False)  # Ensure the line is not clipped by the axis\n",
    "                ax.add_artist(line)     # Add the line as an artist\n",
    "\n",
    "    # Set grid to dashed and also turn minor grid on\n",
    "    ax.grid(which='major', linestyle='--')\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='minor', linestyle=':')\n",
    "\n",
    "    # Set xticks and xticklabels\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels, rotation = 0, ha = 'center')\n",
    "\n",
    "    # Setup labels correctly\n",
    "    # parse ylabel\n",
    "    if ylabel:\n",
    "        ylabel = ylabel.replace('mae', 'Mean Absolute Error').replace('mse', 'Mean Squared Error').replace('accuracy', 'Accuracy')\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    # Set scale\n",
    "    if xlog: ax.set_xscale('log')\n",
    "    if ylog: ax.set_yscale('log')\n",
    "\n",
    "    # Setup the title \n",
    "    if title: ax.set_title(title)\n",
    "\n",
    "    # Add the info label\n",
    "    t = None\n",
    "    if len(info_label) > 0:\n",
    "        # Get axis position in figure-relative coordinates\n",
    "        axis_position = ax.get_position()  # Returns (x0, y0, width, height)\n",
    "        y_top = axis_position.y1 + 0.03  # Slightly above the top of the axis (in figure-relative coordinates)\n",
    "        # Create label\n",
    "        t = create_label(ax, info_label, 0.5, y_top, fontsize=9, border_color=\"black\", padding=0.5, num_columns=2)\n",
    "    \n",
    "    if show:\n",
    "        plt.show(block=False)  # Show without blocking the PyQt5 event loop\n",
    "    else:\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    \"\"\" Restore the default configuration \"\"\"\n",
    "    # Set the 'hatch.linewidth' back to its original value\n",
    "    plt.rcParams['hatch.linewidth'] = old_linewidth\n",
    "    # Set the 'grid.color' back to its original value\n",
    "    plt.rcParams['grid.color'] = old_grid_color\n",
    "\n",
    "    return ax.figure, ax, t, bars\n",
    "\n",
    "def plot_boxplot(subplotters, \n",
    "                 ax = None, y = 'mean', metric = None, colors = None,\n",
    "                 ylims = None, title = None, xlog = False, ylog = False,\n",
    "                 show = False, info_label = None, standalone = True, \n",
    "                 baseline = None, remove_baseline = False, single_out = 'random', \n",
    "                 cmap = 'seismic', filename = None, ylabel = None,\n",
    "                 sorter = 'mean',\n",
    "                 **kwargs):\n",
    "\n",
    "    # Assert sorter \n",
    "    assert sorter in ['median', 'mean', 'max', 'min', 'std'], 'Invalid sorter'\n",
    "\n",
    "    # Loop thru each plotter and get the VUSs\n",
    "    VUCs = []\n",
    "    for method in subplotters:\n",
    "        # Loop thru configs \n",
    "        for config in subplotters[method]:\n",
    "            # Get the plotter obj\n",
    "            plotter = subplotters[method][config]\n",
    "            # Get the vuc\n",
    "            VUCs += [{'method': method, 'config': config, **plotter.vus.loc['vus'].to_dict()}]\n",
    "\n",
    "    # Convert VUCs to a dataframe\n",
    "    df = pd.DataFrame(VUCs)\n",
    "    # Sort by vus \n",
    "    df = df.sort_values(sorter, ascending = metric.lower() not in ['accuracy', 'acc'])\n",
    "\n",
    "    # Xrange is always the number of methods\n",
    "    # ylims\n",
    "    if ylims is None:\n",
    "        ylims = (0.95*df['min'].min(), 1.05*df['max'].max())\n",
    "\n",
    "    # Create color mapper \n",
    "    # Get the min and max values\n",
    "    vmin = (df['median'] - df['std']).min()\n",
    "    vmax = (df['median'] + df['std']).max()\n",
    "    # Create a color palette\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    # Normalize the values\n",
    "    norm = plt.Normalize(vmin, vmax)\n",
    "    # Create lambda function to map any value to color later \n",
    "    color_mapper = lambda x: cmap(norm(x))\n",
    "    hatch_styles = {'auc': '**', 'vus': '//'}\n",
    "\n",
    "    # If ax is none, create a new figure\n",
    "    if ax is None or standalone:\n",
    "        fig, ax = plt.subplots(figsize = (7, 10))\n",
    "        wsbmr.utils.mark_figure_as_deletable(fig)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    \n",
    "    # Initialize the width, x of the bar\n",
    "    bar_w = 0.2\n",
    "    bar_space = 0.1 # Space between method bars (same method are not spaced)\n",
    "    lw = 0.0125\n",
    "\n",
    "    # Store old value of 'hatc.linewidth'\n",
    "    old_linewidth = plt.rcParams['hatch.linewidth']\n",
    "    # Set the linewidth of the hatch lines\n",
    "    plt.rcParams['hatch.linewidth'] = 0.3\n",
    "    plt.rcParams[\"lines.solid_capstyle\"] = \"butt\"\n",
    "    old_grid_color = plt.rcParams['grid.color']\n",
    "    plt.rcParams['grid.color'] = (0.5, 0.5, 0.5, 0.3)\n",
    "\n",
    "    # Group by method \n",
    "    g = df.groupby('method', sort = False)\n",
    "\n",
    "    # Set ylims \n",
    "    ax.set_ylim(ylims)\n",
    "    # Set ticks params here (we need them to get the size of the xticklabels)\n",
    "    ax.tick_params(axis='x', labelsize=9) \n",
    "\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "\n",
    "    # Find the position of the corresponding xtick label\n",
    "    label = ax.get_xticklabels()[0]  # Get the Text object for the label\n",
    "\n",
    "    # Use `get_window_extent` to find the label's extent in display space (optional)\n",
    "    renderer = fig.canvas.get_renderer()\n",
    "    bbox = label.get_window_extent(renderer=renderer)\n",
    "\n",
    "    # Convert the bounding box to data coordinates\n",
    "    inv = ax.transData.inverted()\n",
    "    bbox_data = inv.transform(bbox)\n",
    "\n",
    "    # Use the bottom of the bbox as the y-coordinate for the line\n",
    "    label_y_offset = bbox_data[1][1]  # The top edge of the label in data coordinates\n",
    "    label_new_line_height = bbox_data[1][1] - bbox_data[0][1]  # The height of the label in data coordinates\n",
    "\n",
    "    # Now loop thru methods\n",
    "    boxes = []\n",
    "    x = 0\n",
    "    for i, (method, group) in enumerate(g):\n",
    "        # Loop thru configs, vus\n",
    "        nconfigs = len(group)\n",
    "        for j, (_, row) in enumerate(group.iterrows()):\n",
    "        \n",
    "            config = row['config']\n",
    "            median = row['median']\n",
    "            std = row['std']\n",
    "            max = row['max']\n",
    "            min = row['min']\n",
    "\n",
    "            # Get the x position of the box\n",
    "            x = i*(bar_w + bar_space) + j*bar_w\n",
    "            \n",
    "            # Now get all four coordinates, for simplicity \n",
    "            x0, x1, y0, y1, ym = x, x + bar_w, median - std, median + std, median\n",
    "\n",
    "            # Get this bar's value\n",
    "            c = color_mapper(y1)\n",
    "            hs = hatch_styles['vus']\n",
    "            if single_out is not None:\n",
    "                if single_out == method:\n",
    "                    #c = (1, 1, 1, 1) if btype == 'AUC' else (0, 0, 0, 1)\n",
    "                    c = (0, 0, 0, 1)\n",
    "                    hs = 'o'\n",
    "\n",
    "            # Create a box going from the median to the top of the box\n",
    "            # The color of this box will be the equivalent of the bottom value of the box \n",
    "            ptop = ax.fill_between([x0, x1], ym, y1, \n",
    "                                    color=c[:-1] + (0.3,), \n",
    "                                    edgecolor = 'k', \n",
    "                                    linewidth = 0.5)\n",
    "            # Add hatch to this patch we just created \n",
    "            ptop.set_hatch('//')\n",
    "\n",
    "            # And now one from the median down to the bottom of the box\n",
    "            pbot = ax.fill_between([x0, x1], y0, ym, \n",
    "                                    color=c[:-1] + (0.7,), \n",
    "                                    edgecolor = 'k', \n",
    "                                    linewidth = 0.5)\n",
    "            # Add hatch to this patch we just created\n",
    "            pbot.set_hatch('\\\\\\\\')\n",
    "\n",
    "            # Add a line for the median\n",
    "            m = ax.plot([x0, x1], [ym, ym], color='k', linewidth = 1.4)\n",
    "\n",
    "            \"\"\" Add whiskers now \"\"\"\n",
    "            # Top whisker \n",
    "            wx0, wx1, wy0, wy1 = x + bar_w/2 - lw/2, x + bar_w/2 + lw/2, median + std, max\n",
    "            # try this with a patch instead of a line \n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            ax.imshow([[wy1, wy1], [wy0, wy0]], \n",
    "                cmap = cmap, \n",
    "                extent = [wx0, wx1, wy0, wy1],\n",
    "                interpolation = 'bicubic', \n",
    "                vmin = vmin, vmax = vmax,\n",
    "                alpha = 0.8\n",
    "            )\n",
    "            \n",
    "            # Create a Rectangle patch with the desired border color\n",
    "            rect = plt.Rectangle((wx0, wy0), lw, wy1-wy0, \n",
    "                                edgecolor='k', linewidth = 0.4, facecolor='none')\n",
    "            # Add the patch to the Axes\n",
    "            ax.add_patch(rect)\n",
    "            # Finally, add the whisker line (horizontal line)\n",
    "            ax.plot([x + bar_w/2 - lw, x + bar_w/2 + lw], [wy0, wy0], color='k', linewidth = 0.1)\n",
    "\n",
    "            # Bottom whisker \n",
    "            wx0, wx1, wy0, wy1 = x + bar_w/2 - lw/2, x + bar_w/2 + lw/2, min, median - std\n",
    "            # try this with a patch instead of a line \n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            ax.imshow([[wy1, wy1], [wy0, wy0]], \n",
    "                cmap = cmap, \n",
    "                extent = [wx0, wx1, wy0, wy1],\n",
    "                interpolation = 'bicubic', \n",
    "                vmin = vmin, vmax = vmax,\n",
    "                alpha = 0.8\n",
    "            )\n",
    "\n",
    "            # Create a Rectangle patch with the desired border color\n",
    "            rect = plt.Rectangle((wx0, wy0), lw, wy1-wy0, \n",
    "                                edgecolor='k', linewidth = 0.4, facecolor='none')\n",
    "            # Add the patch to the Axes\n",
    "            ax.add_patch(rect)\n",
    "            # Finally, add the whisker line (horizontal line)\n",
    "            ax.plot([x + bar_w/2 - lw, x + bar_w/2 + lw], [wy1 + 0.01, wy1 - 0.01], color='k', linewidth = 1)\n",
    "            line = mlines.Line2D(\n",
    "                    [x + bar_w/2 - lw, x + bar_w/2 + lw],           # x-coordinates\n",
    "                    [wy1, wy1],        # y-coordinates (outside the plot area)\n",
    "                    color=\"black\",\n",
    "                    lw=0.8\n",
    "                )\n",
    "            # Add the line to the plot\n",
    "            ax.add_artist(line)\n",
    "\n",
    "            # # Now let's get the actual data points for this method \n",
    "            # dfm = subplotters[method][config].curves\n",
    "            # # Make sure len(dfm) > 1, otherwise just pick the only point\n",
    "            # points = dfm['auc'].values\n",
    "            # points_tmrs = dfm['tmr'].values\n",
    "            # if 'tmr_color' in dfm:\n",
    "            #     pointcols = dfm['tmr_color'].values\n",
    "            # else:\n",
    "            #     pointcols = [cmapper(p) for p in points_tmrs]\n",
    "            \n",
    "            # # Get the color for each point \n",
    "            # #pointcols = [cmapper(p) for p in points]\n",
    "            # ax.scatter([i+1.5]*len(points), points, edgecolor = 'k', linewidth = 0.4, alpha = 0.8, color = pointcols, s = 30)\n",
    "            \n",
    "            # Append to boxes\n",
    "            #boxes.append([ptop, pbot])\n",
    "\n",
    "            # Add a label on top of the box with the value of the VUS\n",
    "            ax.text(x + bar_w/2, max + label_new_line_height/2, f'{median:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "            # Add xlabel to list \n",
    "            xticks += [x + bar_w/2]\n",
    "            sp = \"\".join(['\\n']*((i+j)%2))\n",
    "            mstr = method.replace('_', '\\n').replace(' ', '\\n')\n",
    "            mstr = mstr.replace('delta', r'$\\Delta$')\n",
    "            xticklabels += [f'{sp}{mstr}\\n{config}' if nconfigs > 1 else f'{sp}{mstr}']\n",
    "\n",
    "            # Add a line to connect the bar to the xticklabel underneath (only if i+j is odd)\n",
    "            if (i+j) % 2 == 1:\n",
    "                line = mlines.Line2D(\n",
    "                    [x + bar_w/2, x + bar_w/2],           # x-coordinates\n",
    "                    [-label_new_line_height, 2*label_new_line_height],        # y-coordinates (outside the plot area)\n",
    "                    color=\"black\",\n",
    "                    lw=0.8\n",
    "                )\n",
    "                line.set_clip_on(False)  # Ensure the line is not clipped by the axis\n",
    "                ax.add_artist(line)     # Add the line as an artist\n",
    "\n",
    "    # Set grid to dashed and also turn minor grid on\n",
    "    ax.grid(which='major', linestyle='--')\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='minor', linestyle=':')\n",
    "\n",
    "    # Update xlims\n",
    "    ax.set_xlim(-bar_w/2 - bar_space, x + bar_w + bar_space)\n",
    "\n",
    "    # Set xticks and xticklabels\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels, rotation = 0, ha = 'center')\n",
    "\n",
    "    # Setup labels correctly\n",
    "    # parse ylabel\n",
    "    if ylabel:\n",
    "        ylabel = ylabel.replace('mae', 'Mean Absolute Error').replace('mse', 'Mean Squared Error').replace('accuracy', 'Accuracy')\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    # Set scale\n",
    "    if xlog: ax.set_xscale('log')\n",
    "    if ylog: ax.set_yscale('log')\n",
    "\n",
    "    # Setup the title \n",
    "    if title: ax.set_title(title)\n",
    "\n",
    "    ax.set_aspect('auto')\n",
    "    # if vmin == vmax:\n",
    "    #     vmin = 0\n",
    "    #     vmax = 1\n",
    "    # if np.isnan(vmin) or np.isnan(vmax):\n",
    "    #     vmin = 0\n",
    "    #     vmax = 1\n",
    "    # if np.isinf(vmin) or np.isinf(vmax):\n",
    "    #     vmin = 0\n",
    "    #     vmax = 1\n",
    "    # ax.set_ylim(0.95*vmin, 1.05*vmax)\n",
    "    ax.set_ylim(ylims)\n",
    "\n",
    "    # Add the info label\n",
    "    t = None\n",
    "    if len(info_label) > 0:\n",
    "        # Get axis position in figure-relative coordinates\n",
    "        axis_position = ax.get_position()  # Returns (x0, y0, width, height)\n",
    "        y_top = axis_position.y1 + 0.03  # Slightly above the top of the axis (in figure-relative coordinates)\n",
    "        # Create label\n",
    "        t = create_label(ax, info_label, 0.5, y_top, fontsize=9, border_color=\"black\", padding=0.5, num_columns=2)\n",
    "    \n",
    "    if show:\n",
    "        plt.show(block=False)  # Show without blocking the PyQt5 event loop\n",
    "    else:\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    \"\"\" Restore the default configuration \"\"\"\n",
    "    # Set the 'hatch.linewidth' back to its original value\n",
    "    plt.rcParams['hatch.linewidth'] = old_linewidth\n",
    "    # Set the 'grid.color' back to its original value\n",
    "    plt.rcParams['grid.color'] = old_grid_color\n",
    "\n",
    "\n",
    "    return ax.figure, ax, t, boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a container for the comparison plots \n",
    "comparison_ct = pg.CollapsibleContainer(\"ğŸ§º Comparison\", layout='vertical')\n",
    "\n",
    "# Add to documnt\n",
    "tabber.append(comparison_ct)\n",
    "\n",
    "for m in bmk.metric_names:\n",
    "    # Create a container for the comparison plots\n",
    "    ct = pg.CollapsibleContainer(f'{m}', layout = 'vertical')\n",
    "\n",
    "    # Add to group\n",
    "    comparison_ct.append(ct)\n",
    "\n",
    "    _m = m.lower()\n",
    "\n",
    "    subplotters = {}\n",
    "    for method, exp in exps.items():\n",
    "        if method not in subplotters:\n",
    "            subplotters[method] = dict()\n",
    "        subplotters[method][exp.name] = wsbmr.gui.plotter.ExperimentsPlotter(exp.results, \n",
    "                                                                            metric = _m)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a container for the barplot\n",
    "    ct2 = pg.CollapsibleContainer('ğŸ“Š Bar plot', layout = 'vertical')\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize = (10, 5))\n",
    "\n",
    "\n",
    "    plot_barplot(subplotters, \n",
    "                    ax = ax, y = 'mean', metric = _m,\n",
    "                    info_label=[], standalone = False, remove_baseline = True, baseline = 'random')  \n",
    "                    #  ylims = None, title = None, xlog = False, ylog = False,\n",
    "                    #  show = False, standalone = True, \n",
    "                    #  baseline = None, remove_baseline = False, single_out = 'random', \n",
    "                    #  cmap = 'viridis', filename = None, ylabel = None,\n",
    "                    #  **kwargs)\n",
    "\n",
    "    # Create plot img \n",
    "    p = pg.Plot(fig)\n",
    "    ct2.append(p)\n",
    "    # Append to group\n",
    "    ct.append(ct2)\n",
    "    # Close ax \n",
    "    plt.close(fig)\n",
    "\n",
    "    # And now the same for boxplot\n",
    "    # Create a container for the barplot\n",
    "    ct3 = pg.CollapsibleContainer('â§® Box plot', layout = 'vertical')\n",
    "\n",
    "    fig2, ax2 = plt.subplots(1,1, figsize = (10, 5))\n",
    "\n",
    "    plot_boxplot(subplotters, \n",
    "                    ax = ax2, y = 'mean', metric = _m,\n",
    "                    info_label=[], standalone = False, remove_baseline = True, baseline = 'random')  \n",
    "\n",
    "    # Create plot img \n",
    "    p = pg.Plot(fig2)\n",
    "    ct3.append(p)\n",
    "    # Append to group\n",
    "    ct.append(ct3)\n",
    "    # Close ax \n",
    "    plt.close(fig2)\n",
    "\n",
    "    # Save doc\n",
    "    doc.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsbmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
